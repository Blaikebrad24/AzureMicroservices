# ==========================================================
# ALTERNATIVE: lua-resty-openidc (OpenResty-based OIDC)
# ==========================================================
#
# This file provides an alternative to the Flask OIDC proxy
# using OpenResty's lua-resty-openidc module. It handles the
# entire OIDC Authorization Code Flow natively within Nginx
# without needing a separate Python container.
#
# ── HOW TO USE THIS APPROACH ──
#
# 1. Change the Nginx Dockerfile base image:
#    FROM openresty/openresty:1.25.3.2-alpine-fat
#
# 2. Install lua-resty-openidc in the Dockerfile:
#    RUN luarocks install lua-resty-openidc
#
# 3. Rename this file to remove .disabled:
#    mv lua-oidc.conf.disabled lua-oidc.conf
#
# 4. Remove or rename default.conf (they conflict):
#    mv default.conf default.conf.disabled
#
# 5. Remove the flask-oidc-proxy service from docker-compose.yml
#
# ── KNOWN ISSUES / GOTCHAS ──
#
# - DNS Resolution in Docker:
#   You MUST add 'resolver 127.0.0.11 valid=1s;' for Docker's
#   internal DNS to resolve container names. Without this,
#   lua-resty-openidc cannot find the Keycloak container.
#
# - Session Storage:
#   By default, lua-resty-openidc uses shared memory (shm).
#   For production, use lua-resty-session with Redis backend:
#     set $session_storage redis;
#     set $session_redis_host redis;
#     set $session_redis_port 6379;
#     set $session_redis_auth redispassword;
#
# - Keycloak Compatibility:
#   lua-resty-openidc 1.7.6+ has known session handling issues
#   with Keycloak 23+. Test thoroughly before using in production.
#
# - Token Refresh:
#   lua-resty-openidc handles token refresh automatically, but
#   the refresh behavior is less configurable than the Flask proxy.
#
# - Custom Auth Logic:
#   With Flask, you have full Python flexibility for custom auth
#   logic (e.g., role-based routing, custom claims extraction).
#   With lua-resty-openidc, custom logic requires Lua scripting.
#
# ── WHY FLASK PROXY WAS CHOSEN ──
#
# The Flask proxy approach was chosen for this project because:
# 1. More control over the auth flow and session management
# 2. Easier to debug (Python vs Lua)
# 3. Simpler to add custom auth logic
# 4. Better logging and error handling
# 5. Team familiarity with Python
#
# However, lua-resty-openidc has advantages:
# 1. Fewer containers (no separate Flask service)
# 2. Lower latency (no HTTP hop to Flask)
# 3. Single process handles both proxy and auth
#
# ==========================================================

# lua_shared_dict discovery 1m;
# lua_shared_dict jwks 1m;
# lua_shared_dict introspection 10m;
# lua_shared_dict sessions 10m;
#
# upstream frontend {
#     server frontend:3000;
# }
#
# server {
#     listen 443 ssl;
#     server_name localhost;
#
#     ssl_certificate     /etc/nginx/certs/server.crt;
#     ssl_certificate_key /etc/nginx/certs/server.key;
#     ssl_protocols TLSv1.2 TLSv1.3;
#
#     # CRITICAL: Docker DNS resolver for container name resolution
#     resolver 127.0.0.11 valid=1s ipv6=off;
#
#     # Session configuration (shared memory for development)
#     set $session_storage shm;
#     set $session_shm_store sessions;
#     set $session_cookie_samesite Lax;
#     set $session_secret super-secret-key-change-in-production;
#
#     # For Redis-backed sessions (recommended for production):
#     # set $session_storage redis;
#     # set $session_redis_host redis;
#     # set $session_redis_port 6379;
#     # set $session_redis_auth redispassword;
#
#     # Auth endpoints handled by lua-resty-openidc
#     location / {
#         access_by_lua_block {
#             local opts = {
#                 -- OIDC Discovery URL (uses Docker internal hostname)
#                 discovery = "http://keycloak:8080/realms/app-realm/.well-known/openid-configuration",
#
#                 -- Client credentials
#                 client_id = "nginx-proxy-client",
#                 client_secret = "changeme",
#
#                 -- Redirect URI for the callback
#                 redirect_uri = "https://localhost/callback",
#
#                 -- Scopes to request
#                 scope = "openid email profile",
#
#                 -- Session contents
#                 session_contents = {id_token=true, access_token=true, user=true},
#
#                 -- Token endpoint auth method
#                 token_endpoint_auth_method = "client_secret_post",
#
#                 -- Logout path
#                 logout_path = "/auth/logout",
#
#                 -- Redirect after logout
#                 post_logout_redirect_uri = "https://localhost",
#
#                 -- SSL verification (disable for self-signed certs in dev)
#                 ssl_verify = "no",
#             }
#
#             -- Authenticate the request
#             local res, err = require("resty.openidc").authenticate(opts)
#             if err then
#                 ngx.status = 500
#                 ngx.log(ngx.ERR, "OIDC authentication error: ", err)
#                 ngx.say("Authentication error. Please try again.")
#                 ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)
#             end
#
#             -- Set auth headers for upstream services
#             ngx.req.set_header("X-Auth-User", res.id_token.preferred_username or "")
#
#             -- Extract realm roles from the token
#             local roles = res.id_token.realm_roles or {}
#             if type(roles) == "table" then
#                 ngx.req.set_header("X-Auth-Roles", table.concat(roles, ","))
#             else
#                 ngx.req.set_header("X-Auth-Roles", tostring(roles))
#             end
#
#             ngx.req.set_header("X-Auth-Email", res.id_token.email or "")
#         }
#
#         proxy_pass http://frontend;
#         proxy_set_header Host $host;
#         proxy_set_header X-Real-IP $remote_addr;
#         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
#         proxy_set_header X-Forwarded-Proto $scheme;
#
#         # WebSocket support
#         proxy_http_version 1.1;
#         proxy_set_header Upgrade $http_upgrade;
#         proxy_set_header Connection "upgrade";
#     }
#
#     error_page 500 502 503 504 /50x.html;
#     location = /50x.html {
#         root /usr/share/nginx/html;
#     }
# }
#
# server {
#     listen 80;
#     server_name localhost;
#     return 301 https://$host$request_uri;
# }
